<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="To be a hacker">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>梯度下降 - Harry的博客 | Harry's Blog</title>

    <link rel="canonical" href="http://words.hackiey.com/2016/07/17/gradient-descent/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="http://cdn.staticfile.org/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Hackiey</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/in-post/ann/ann2.jpg" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        background-image: url('/img/in-post/ann/ann2.jpg')
    }
</style>
<header class="intro-header" >
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#机器学习" title="机器学习">机器学习</a>
                        
                    </div>
                    <h1>梯度下降</h1>
                    
                    
                    <h2 class="subheading"></h2>
                    
                    <span class="meta">Posted by Harry on July 17, 2016</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

				<p>梯度下降是一个最优化算法，通过迭代的方式寻找代价函数的最小值，梯度下降是一个非常常用的算法，不仅仅可以应用在线性回归问题中，还被广泛应用于机器学习中的众多领域，</p>

<h3 id="section">基本思想</h3>

<p>定义<script type="math/tex">J(\theta_0,\theta_1)={1\over 2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2</script></p>

<p>目标： <script type="math/tex">min_{\theta_0,\theta_1}J(\theta_0,\theta_1)</script></p>

<p>到目前为止，我们仍然只使用了一个变量x，所以代价函数的变量只有<script type="math/tex">\theta_0（截距项）和\theta_1</script>，<script type="math/tex">min_{\theta_0,\theta_1}J(\theta_0,\theta_1)</script>指的是选择合适的<script type="math/tex">\theta_0和\theta_1</script>使得<script type="math/tex">J(\theta_0,\theta_1)</script>取得最小值。</p>

<p>在<a href="/2016/07/16/linear-regression">线性回归</a>中的末尾为了简化，我们设<script type="math/tex">\theta_0</script>为0，画出了<script type="math/tex">J关于\theta_1</script>的图像，是一个一元二次函数的图像，现在将<script type="math/tex">\theta_0</script>加入进来，画一幅二元二次图像。</p>

<blockquote>
  <p>图片来自coursera的机器学习课程梯度下降部分的视频中（<a href="https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent">视频连接</a>）。</p>
</blockquote>

<p><img src="/img/in-post/machine-learning/gradient-descent/cost-function-square.png" alt="cost function(square)" /></p>

<p>熟悉微积分的人都知道，在曲线的某一点上斜率就是曲线在这一点的导数，这就是梯度的概念，梯度是曲线上升最快的方向，因此想要最快的到达曲线的底部（最小值处），就要求出这一点的导数，朝着相反的方向走一小步，再求新的位置的导数并继续移动一小步，直到达到最小值点。应用在上图的曲面中，要在每一个位置求出两个变量（<script type="math/tex">\theta_0和\theta_1</script>）的偏导数，这时梯度变成了一个二维向量。随机落在曲面上一点时，迭代寻找最小值的过程如下图：</p>

<p><img src="/img/in-post/machine-learning/gradient-descent/gradient-descent-1.png" alt="cost function(square)" /></p>

<h3 id="section-1">推导</h3>

<p>现在你对梯度下降有了一个直观的认识，尽管你不需要了解相关的数学知识也可以完成训练过程，但我仍然强烈建议你阅读完这一部分，这对算法的理解有很多帮助。当然直接跳过这一部分也不会影响实际应用。</p>

<p>为了得到梯度下降的一般形式，需要把线性回归的变量数量扩展到n个，即多元线性回归，现在定义假设函数为：</p>

<script type="math/tex; mode=display">h_\theta(x)=\theta_0+\theta_1 x_1+\theta_2 x_2+...+\theta_n x_n</script>

<p>为了表示方便，设 <script type="math/tex">x_0 = 1</script> ：</p>

<script type="math/tex; mode=display">h_\theta(x)=\theta_0 x_0+\theta_1 x_1+\theta_2 x_2+...+\theta_n x_n \tag1</script>

<p>写成向量形式，<script type="math/tex">\theta</script>是一个n+1维向量：</p>

<script type="math/tex; mode=display">h_\theta(x) =  \theta \cdot  x</script>

<p>新的代价函数公式为：</p>

<script type="math/tex; mode=display">J( \theta)={1\over 2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 \tag2</script>

<p>定义代价函数<script type="math/tex">J(\theta)</script>的梯度为：</p>

<script type="math/tex; mode=display">\nabla J( \theta)\equiv \left [
		{\partial J\over \partial \theta_0} ,
		{\partial J\over \partial \theta_1} ,
		... ,
		{\partial J\over \partial \theta_n} ,
	\right ]\tag{3}</script>

<p>梯度是一个方向，获取到移动的方向后，接下来定义<script type="math/tex">\theta</script>的更新规则，“ := ”是赋值的意思：</p>

<script type="math/tex; mode=display">\theta :=  \theta+ \Delta  \theta</script>

<p>其中：</p>

<script type="math/tex; mode=display">\Delta  \theta=\alpha \nabla J( \theta) \tag4</script>

<p>其中<script type="math/tex">\alpha</script>是学习速率，它决定了在向误差最小值移动的速度——一步迈出去走多远（可以证明，在<script type="math/tex">\alpha</script>足够小的情况下，梯度下降算法总能收敛）。为了获取最终的权值更新公式(<script type="math/tex">\theta_i</script>的更新公式)，写出其分量形式：</p>

<script type="math/tex; mode=display">\theta_j := \theta_j+\Delta \theta_j</script>

<p>其中：</p>

<script type="math/tex; mode=display">\Delta \theta_j=-\alpha {\partial J\over\partial \theta_j} \tag{5}</script>

<p>现在来推导公式中的<script type="math/tex">\partial J\over\partial \theta_j</script>：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
{\partial J\over \partial \theta_j} & = {\partial \over \partial \theta_j}{1\over 2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 = {1\over 2m}\sum_{i=1}^m{\partial\over \partial \theta_j}(h_\theta(x^{(i)}) - y^{(i)})^2\\
& = {1\over 2m}\sum_{i=1}^m 2(h_\theta(x^{(i)}) - y^{(i)}) {\partial\over \partial \theta_j}(h_\theta(x^{(i)}) - y^{(i)}) \\
& = {1\over m}\sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}){\partial \over \partial \theta_j}(\theta_0 x_0^{(i)} + \theta_1 x_1^{(i)} + ... + \theta_j x_j^{(i)} + ...+ \theta_n x_n^{(i)}-y^{(i)}) \\
{\partial J\over \partial \theta_j} & = {1 \over m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \tag{6}\\
\end{align} %]]></script>

<p>其中<script type="math/tex">x_j^{(i)}</script>是第i个训练样例的第j个输入，将(6)代入(5)中得：</p>

<script type="math/tex; mode=display">\Delta \theta_j=- \alpha {1\over m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}</script>

<p>最终:</p>

<script type="math/tex; mode=display">\theta_j := \theta_j - \alpha {1\over m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} \tag7</script>

<h3 id="section-2">算法</h3>

<p>得到具体的更新公式之后，梯度下降的算法就十分清晰了：</p>

<hr />
<p><strong>GRADIENT DESCENT (training_examples,<script type="math/tex">\alpha</script>)</strong>
(n&gt;=1，<script type="math/tex">j\in[0,n+1]</script>)</p>

<ul>
  <li>(1)初始化每个<script type="math/tex">\theta_j</script>为某个小的随机值</li>
  <li>(2)遇到终止条件之前，做以下操作：
    <ul>
      <li>(2.1)对于训练样例training_examples中的每个<script type="math/tex">(x^{(i)},y^{(i)})</script>，做：
        <ul>
          <li>计算<script type="math/tex">h_\theta(x^{(i)})</script></li>
          <li>对于每个权值<script type="math/tex">\theta_j</script>，做：
  <script type="math/tex">\Delta \theta_j := \Delta \theta_j - \alpha(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}		\tag8</script></li>
        </ul>
      </li>
      <li>(2.2)对于每个权值<script type="math/tex">\theta_j</script>,做：
  <script type="math/tex">\theta_j:=\theta_j+{1\over m}\Delta \theta_j\tag9</script></li>
    </ul>
  </li>
</ul>

<p>这里初看上去似乎有些疑惑，<script type="math/tex">\sum_{i=1}^m</script>的求和式不见了，其实整个(2.1)步就在做这一求和工作，并在(2.2)步进行更新。
这里有一个隐含的规则，先执行(2.1)再执行(2.2)意味着在计算所有的<script type="math/tex">\Delta \theta_j</script>的时候都是使用的上一轮<script type="math/tex">\theta</script>，这条规则叫做<strong>同步更新</strong>，即在更新第j+1个权值时，要使用与更新j时一样——都是上轮迭代的权值。</p>

<h3 id="section-3">缺陷和改进</h3>

<p>你也许已经注意到，梯度下降虽然可以保证收敛，但无法保证一定可以收敛在全局最小值，例如在代价函数曲面图上选择另外一个点就会收敛在另外一个局部最小值中：</p>

<p><img src="/img/in-post/machine-learning/gradient-descent/gradient-descent-2.png" alt="cost function 2" /></p>

<p>通常情况下你不需要为这种情况担心，像这样拥有多个局部极小值的情况是很少见的，即使遇到多个局部极小值也不要紧，因为使用梯度下降一般都会运行良好，训练出来的结果也都会令人满意。</p>

<p>通过观察公式(7)，你会发现每一次迭代都要计算一遍所有的训练样例，这样的计算是缓慢而且代价昂贵的，因此有人提出了随机梯度下降（stochastic gradient descent），它的思想是使用单个样例更新权值而不是基于所有的训练样例，将标准的梯度下降稍加修改就是下面的随机梯度下降。</p>

<h5 id="section-4">随机梯度下降</h5>

<p>由于随机梯度下降在每一次迭代时不需要计算所有的训练样例，因此随机梯度下降的代价函数为：</p>

<script type="math/tex; mode=display">J^{(i)}(\theta)={1\over 2}h_\theta(x^{(i)}-y^{(i)})^2 \tag{10}</script>

<p>对(10)求<script type="math/tex">\theta_j</script>偏导数最终求得权值更新公式为：</p>

<script type="math/tex; mode=display">\theta_j=- \alpha(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\tag{11}</script>

<p>将(8)替换为(11)，并删掉(9)就是随机梯度下降算法。</p>


                <hr>

                


                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2016/07/16/linear-regression/" data-toggle="tooltip" data-placement="top" title="线性回归">&larr; Previous Post</a>
                    </li>
                    
                    
                </ul>


                

                
                <!-- disqus 评论框 start -->
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                <!-- disqus 评论框 end -->
                

            </div>

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
        				
                            
        				
                            
                				<a href="/tags/#机器学习" title="机器学习" rel="6">
                                    机器学习
                                </a>
                            
        				
                            
                				<a href="/tags/#人工神经网络" title="人工神经网络" rel="4">
                                    人工神经网络
                                </a>
                            
        				
        			</div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">
                    
                        <li><a href="http://www.hackiey.com">Hackiey</a></li>
                    
                        <li><a href="http://gty.org.in/">David Gu</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>





<!-- disqus 公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "hackiey";
    var disqus_identifier = "/2016/07/17/gradient-descent";
    var disqus_url = "http://words.hackiey.com/2016/07/17/gradient-descent/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus 公共JS代码 end -->




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("http://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    


                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/hackiey">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Hackiey 2016
                    <br>
<!--                     Theme by <a href="http://huangxuan.me">Hux</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true" >
                    </iframe> -->
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("http://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->




<!-- Image to hack wechat -->
<img src="/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->
<!-- script -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>
