---
layout:     post
title:      "人工神经网络（感知器）（一）"
subtitle:   ""
date:       2016-05-13 20:00:00
author:     "Harry"
tags:
    - 机器学习
    - 人工神经网络
---

我曾经一度以为所有的ANN就是由感知器(pecrceptron)组成的，但实际上，感知器只是一种ANN的基础单元。

### 感知器

感知器以一个实数值向量作为输入，计算这些输入的线性组合，如果结果大于某个**阈值**，就输出1，否则输出-1。如果输入为$$x_1$$到$$x_n$$，那么感知器计算的输出为:

$$
	o(x_1,...,x_n)=\begin{cases} 
						1,  & \text{if $w_0+w_1x_1+w_2x_2+...+w_nx_n>0$}\\ 
						-1, & \text{otherwise} \\ 
					\end{cases} 			
$$

其中$$w_i$$叫做权值(weight)，是一个**实数常量**，用来决定输入$$x_i$$对感知器输出的贡献率。需要注意的是($$-w_0$$)是一个阈值，如果想要使感知器输出1，其余的$$w_1x_1+...+w_nx_n$$必须要大于($$-w_0$$)。从这里可以看出，`感知器可以做一个二叉分类器，因为它对所有的输入做出1或-1的输出，是线性分类器(linear classifier)的一种。`

![感知器](/img/in-post/ann-perceptron/perceptron.png)

为了简化，可以将$$x_0$$设置为1，不等式可写为$${\sum_{i=0}^nw_ix_i}>0$$，这样可以表示为**向量**$$\vec w\cdot\vec x>0$$，因此感知器函数可以写为:

$$o(\vec x)=sgn(\vec w\cdot\vec x)$$

### 感知器的表征能力

从上面的几个式子中可以看出来感知器可以做分类，而这个类别只有两种，要么是，要么不是。

>我们可以把感知器看作是n维实例空间(即点空间)中的超平面决策面。对于超平面一侧的实例，感知器输出1，对于另一侧输出-1。

什么是超平面？在N维空间中，任何N-1维的次空间都是超平面，在二维平面中，超平面是一条**直线**，在三维空间中，超平面就是我们日常所理解的平面。

不是所有的正反样例集合都可以恰好被分成两份，可以被分割的称为线性可分(linearly separable)样例集合。

单独的感知器可以表示一些布尔函数。例如在一个有两个输入的感知器中，实现AND函数可以设$$w_0$$为-0.8，$$w_1=w_2=0.5$$，实现OR函数可以设$$w_0$$为-0.3，$$w_1=w_2=0.5$$，还可以实现与非(NAND)和或非(NOR)等函数，使用两层深度的感知器网络就可以实现所有的布尔函数。

>因为阈值单元的网络可以表示大量的函数，而单独的单元不能做到这一点，所以通常我们感兴趣的事学习阈值单元组成的多层网络。

`阈值是一个很重要的概念，它就像y=ax+b中的b，是一个必不可少的常量。`

如何训练一个感知器，这里主要考虑两种训练法则，感知器训练法则(perceptron training rule)和delta法则(delta rule)。这两种算法**保证**收敛到可接受的假设。

### 感知器训练法则

感知器训练法则的过程是，首先生成随机的权值，然后反复地应用感知器到每一个训练样例，如果感知器分类**错误**，那么就根据训练样例来修改权值。**重复这个过程直到感知器能够正确分类所有样例**。

$$
	w_i\leftarrow w_i+\Delta w_i
$$

$$
	\Delta w_i=\eta (t-o)x_i
$$

其中t是训练样例的目标输出，o是感知器的输出，$$\eta$$是学习速率(learning rate)，它是一个很小的数值，并且它有时会随着权调整次数的增加而衰减(`并不是一直不变的`)。

如果训练样例线性可分，且$$\eta$$足够小，那么感知器训练法则可以在**有限次**内收敛到一个能正确分类所有训练样例的权向量。

### 实验

这一节的代码实现了AND函数的学习，在多次实验中，发现使用200个以上的训练数据便可以学习到一个完全正确的AND函数。

`有人说神经网络的缺点之一是不理解权值，以及难以调试，在多个单元组成的网络中有时甚至要靠经验去判断使用多少层和多少个基本单元，我同意这样的说法，但对于这样的结果我会更兴奋，因为这就像我正在理解我自己的大脑。`

感知器所实现的AND函数的权值是可以被理解的，这是一张包含了错误与正确的训练结果图，可以发现，正确的权值中\|$$w_0$$\|始终大于$$w_1和w_2$$。

![感知器训练法则结果](/img/in-post/ann-perceptron/perceptron-result.png)

如果训练样例不是线性可分时，感知器训练法则将无法收敛，下一节会介绍适用于样例不是线性可分时的训练方法——delta法则。